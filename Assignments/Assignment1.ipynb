{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up selenium/ beautifulsoup/ pandas\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up selenium and soup \n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_experimental_option(\"detach\", True)\n",
    "service = Service(executable_path=\"chromedriver.exe\")\n",
    "driver = webdriver.Chrome(service=service, options=options)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_election_page():\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    WebDriverWait(driver, 5).until(\n",
    "            EC.presence_of_element_located((By.CSS_SELECTOR, 'div.tile-h_ymFU.cnn-pcl-13b0kh1'))\n",
    "        )\n",
    "    columns = soup.select('div.tile-h_ymFU.cnn-pcl-13b0kh1[data-testid=\"card\"]')\n",
    "    county_name = ''\n",
    "\n",
    "# Add in delegate numbers from table above\n",
    "    delegate_rows = soup.select('tr.cnn-pcl-1me6450.isWinner-3g_AYM')\n",
    "    candidate_delegates = {} \n",
    "    for row in delegate_rows:\n",
    "        name_element = row.select_one('span[data-testid=\"candidate-name\"]')\n",
    "        candidate = name_element.get_text(strip=True) if name_element else None\n",
    "\n",
    "        delegate_element = row.select_one('td[data-testid=\"delegates\"]')\n",
    "        delegates = int(delegate_element.get_text(strip=True)) if delegate_element else 0\n",
    "\n",
    "        # Initialize the candidate in the dictionary if it doesn't exist\n",
    "        if candidate not in candidate_delegates:\n",
    "            candidate_delegates[candidate] = 0\n",
    "            \n",
    "        # Store the candidate-delegate pair in the dictionary\n",
    "        candidate_delegates[candidate] += delegates\n",
    "\n",
    "\n",
    "    for column in columns: \n",
    "        county_name = soup.select_one('article.core-result div.header-container-1LzJY9 h2').text\n",
    "        table = column.select_one('table.cnn-pcl-1me6450')\n",
    "        rows = table.select('tr.cnn-pcl-1me6450')\n",
    "\n",
    "        for row in rows:\n",
    "            state = soup.select_one('h2.header-2-AOgLYo.cnn-pcl-xk8c6r').get_text().split()[-1]\n",
    "            county = county_name\n",
    "            name_element = row.select_one('span[data-testid=\"candidate-name\"]')\n",
    "            candidate = name_element.get_text(strip=True) if name_element else None\n",
    "\n",
    "            party_element = row.select_one('span[data-testid=\"party-label\"]')\n",
    "            party = party_element.get_text(strip=True).split(',')[0] if party_element else None\n",
    "\n",
    "            incumbent = 'Incumbent' in party_element.get_text(strip=True) if party_element else False\n",
    "            incumbent_status = 'Yes' if incumbent else 'No'\n",
    "\n",
    "            vote_percent_element = row.select_one('td[data-testid=\"votepercent\"]')\n",
    "            percentage = vote_percent_element.get_text(strip=True) if vote_percent_element else None\n",
    "            \n",
    "            vote_count_element = row.select_one('span[data-testid=\"votes\"]')\n",
    "            votes = vote_count_element.get_text(strip=True) if vote_count_element else None\n",
    "\n",
    "            winner = 'Yes' if incumbent_status == 'Yes' else 'No'\n",
    "\n",
    "            delegates = candidate_delegates.get(candidate, 0)\n",
    "\n",
    "            if candidate is not None and votes is not None:\n",
    "                yield {\n",
    "                    'State': state,\n",
    "                    'County': county_name,\n",
    "                    'Candidate': candidate,\n",
    "                    'Party': party,\n",
    "                    'Incumbent': incumbent_status,\n",
    "                    'Votes': votes,\n",
    "                    'Percentage': percentage,\n",
    "                    'Winner': winner,\n",
    "                    'Delegates': delegates\n",
    "                }\n",
    "            # print(data)\n",
    "            \n",
    "    # return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_election_page_special():\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    # WebDriverWait(driver, 5).until(\n",
    "    #         EC.presence_of_element_located((By.CSS_SELECTOR, 'div.tile-h_ymFU.cnn-pcl-13b0kh1'))\n",
    "    #     )\n",
    "    columns = soup.select('article.core-result')\n",
    "    \n",
    "    for column in columns:\n",
    "        print(column.prettify())\n",
    "        county_name = None\n",
    "        table = column.select_one('table.cnn-pcl-1me6450')\n",
    "        rows = table.select('tr.cnn-pcl-1me6450')\n",
    "\n",
    "        for row in rows:\n",
    "            candidate_delegates = {} \n",
    "            name_element = row.select_one('span[data-testid=\"candidate-name\"]')\n",
    "            candidate = name_element.get_text(strip=True) if name_element else None\n",
    "\n",
    "            delegate_element = row.select_one('td[data-testid=\"delegates\"]')\n",
    "            try:\n",
    "                delegates = int(delegate_element.get_text(strip=True)) if delegate_element else 0\n",
    "            except ValueError:\n",
    "            # Handle the case where the text cannot be converted to an integer\n",
    "                    delegates = 0\n",
    "\n",
    "            # Initialize the candidate in the dictionary if it doesn't exist\n",
    "            if candidate not in candidate_delegates:\n",
    "                candidate_delegates[candidate] = 0\n",
    "                \n",
    "            # Store the candidate-delegate pair in the dictionary\n",
    "            candidate_delegates[candidate] += delegates\n",
    "\n",
    "\n",
    "            state = soup.select_one('h2.header-2-AOgLYo.cnn-pcl-xk8c6r').get_text().split()[-1]\n",
    "            party_element = row.select_one('span[data-testid=\"party-label\"]')\n",
    "            party = party_element.get_text(strip=True).split(',')[0] if party_element else None\n",
    "\n",
    "            incumbent = 'Incumbent' in party_element.get_text(strip=True) if party_element else False\n",
    "            incumbent_status = 'Yes' if incumbent else 'No'\n",
    "\n",
    "            vote_percent_element = row.select_one('td[data-testid=\"votepercent\"]')\n",
    "            percentage = vote_percent_element.get_text(strip=True) if vote_percent_element else None\n",
    "            \n",
    "            vote_count_element = row.select_one('span[data-testid=\"votes\"]')\n",
    "            votes = vote_count_element.get_text(strip=True) if vote_count_element else None\n",
    "\n",
    "            winner = 'Yes' if incumbent_status == 'Yes' else 'No'\n",
    "\n",
    "            delegates = candidate_delegates.get(candidate, 0)\n",
    "\n",
    "            if candidate is not None and votes is not None:\n",
    "                yield {\n",
    "                    'State': state,\n",
    "                    'County': county_name,\n",
    "                    'Candidate': candidate,\n",
    "                    'Party': party,\n",
    "                    'Incumbent': incumbent_status,\n",
    "                    'Votes': votes,\n",
    "                    'Percentage': percentage,\n",
    "                    'Winner': winner,\n",
    "                    'Delegates': delegates\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Alabama', 'Arkansas', 'California', 'Colorado', 'Iowa', 'Maine', 'Massachusetts', 'Minnesota', 'North Carolina', 'Oklahoma', 'Tennessee', 'Texas', 'Utah', 'Vermont', 'Virginia']\n"
     ]
    }
   ],
   "source": [
    "states_democratic = ['Alabama', 'American Samoa', 'Arkansas', 'California', 'Colorado', \n",
    "                     'Iowa', 'Maine', 'Massachusetts', 'Minnesota', 'North Carolina',\n",
    "                     'Oklahoma', 'Tennessee', 'Texas', 'Utah', 'Vermont', 'Virginia']\n",
    "states_republican = ['Alabama', 'Alaska', 'Arkansas', 'California', 'Colorado',\n",
    "                     'Maine', 'Massachusetts', 'Minnesota', 'North Carolina', \n",
    "                     'Oklahoma', 'Tennessee', 'Texas', 'Utah', 'Vermont', 'Virginia']\n",
    "states_both = [state for state in states_democratic if state in states_republican]\n",
    "states_both.insert(4, 'Iowa')\n",
    "print(states_both)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix_dem = \"https://edition.cnn.com/election/2024/primaries-and-caucuses/results/\"\n",
    "suffix_dem = \"/democratic-presidential-primary\"\n",
    "prefix_rep = \"https://edition.cnn.com/election/2024/primaries-and-caucuses/results/\"\n",
    "suffix_rep = \"/republican-presidential-primary\"\n",
    "\n",
    "combined_data = [] \n",
    "columns = ['State', 'County', 'Candidate', 'Party', 'Incumbent', 'Votes', 'Percentage', 'Winner', 'Delegates']\n",
    "combined_df = pd.DataFrame(columns=columns)\n",
    "soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "# Append data for Democratic Party \n",
    "for i in states_both:\n",
    "    # modify the state names\n",
    "    state_name = i.lower().replace(\" \", \"-\")\n",
    "    link = f'{prefix_dem}{state_name}{suffix_dem}'\n",
    "    driver.get(link)\n",
    "\n",
    "    wait = WebDriverWait(driver, 1)  # Adjust the timeout value as needed\n",
    "    button = wait.until(EC.element_to_be_clickable((By.CSS_SELECTOR, \"button.rightButton.cnn-pcl-13b0kh1\")))\n",
    "\n",
    "    # Right-click button element \n",
    "    have_button = True\n",
    "    button = driver.find_element(By.CSS_SELECTOR, \"button.rightButton.cnn-pcl-13b0kh1\")\n",
    "\n",
    "    # Display all pages \n",
    "    while have_button: \n",
    "        try:\n",
    "            button = wait.until(EC.element_to_be_clickable((By.CSS_SELECTOR, \"button.rightButton.cnn-pcl-13b0kh1\")))\n",
    "            # Scrape the election page and add data to combined list\n",
    "            for election_data in scrape_election_page():\n",
    "                    if election_data is not None:\n",
    "                        combined_data.append(election_data) \n",
    "            button.click()\n",
    "        except TimeoutException:\n",
    "            have_button = False\n",
    "\n",
    "\n",
    "# Append data for Republican Party \n",
    "for i in states_both:\n",
    "    # modify the state names\n",
    "    state_name = i.lower().replace(\" \", \"-\")\n",
    "    link = f'{prefix_rep}{state_name}{suffix_rep}'\n",
    "    driver.get(link)\n",
    "\n",
    "    wait = WebDriverWait(driver, 1)  # Adjust the timeout value as needed\n",
    "    button = wait.until(EC.element_to_be_clickable((By.CSS_SELECTOR, \"button.rightButton.cnn-pcl-13b0kh1\")))\n",
    "\n",
    "    # Right-click button element \n",
    "    have_button = True\n",
    "    button = driver.find_element(By.CSS_SELECTOR, \"button.rightButton.cnn-pcl-13b0kh1\")\n",
    "\n",
    "    # Display all pages \n",
    "    while have_button: \n",
    "        try:\n",
    "            button = wait.until(EC.element_to_be_clickable((By.CSS_SELECTOR, \"button.rightButton.cnn-pcl-13b0kh1\")))\n",
    "            # Scrape the election page and add data to combined list\n",
    "            for election_data in scrape_election_page():\n",
    "                    if election_data is not None:\n",
    "                        combined_data.append(election_data)\n",
    "            button.click()\n",
    "        except TimeoutException:\n",
    "            have_button = False\n",
    "\n",
    "# Append data for the two special webpages (Alaska and American Samoa)\n",
    "states_special = ['Alaska', 'American Samoa']\n",
    "combined_data = [] \n",
    "for i in states_special: \n",
    "        state_name = i.lower().replace(\" \", \"-\")\n",
    "        prefix = \"https://edition.cnn.com/election/2024/primaries-and-caucuses/results/\"\n",
    "        link = f'{prefix}{state_name}'\n",
    "        driver.get(link)\n",
    "        for election_data in scrape_election_page_special():\n",
    "                        if election_data is not None:\n",
    "                            combined_data.append(election_data)\n",
    "\n",
    "     \n",
    "# for dic in combined_data:\n",
    "#     print(dic)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = pd.DataFrame(combined_data)     \n",
    "print(combined_df.shape)  \n",
    "combined_df.reset_index(inplace=True, drop=True) # <-- Reset the index of the combined dataFrame\n",
    "combined_df.index = combined_df.index + 1 \n",
    "print(combined_df)\n",
    "\n",
    "#combined_df.to_excel('data.xlsx', sheet_name='Assignment_1_Sheet', index=False) # <-- For self-reference\n",
    "combined_df.to_csv('data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up launchbrowser function \n",
    "# create list to store data for each page  \n",
    "# \"for\" loop to loop over pages \n",
    "# convert to pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
